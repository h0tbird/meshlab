#!/usr/bin/env bash

#------------------------------------------------------------------------------
# [i] Initializations
#------------------------------------------------------------------------------

# Bash strict mode
set -euo pipefail

# Change to the execution directory
cd "$(dirname "$0")"/..

# shellcheck source=/dev/null
source lib/common.sh

#------------------------------------------------------------------------------
# [i] Versions
#------------------------------------------------------------------------------

CILIUM_CHART_VERSION='1.16.4'                 # https://artifacthub.io/packages/helm/cilium/cilium
ARGOCD_CHART_VERSION='7.7.10'                 # https://artifacthub.io/packages/helm/argo-cd-oci/argo-cd
ARGOWF_CHART_VERSION='0.45.1'                 # https://artifacthub.io/packages/helm/argo/argo-workflows
PROMETHEUS_CHART_VERSION='26.0.0'             # https://artifacthub.io/packages/helm/prometheus-community/prometheus
GRAFANA_CHART_VERSION='8.6.4'                 # https://artifacthub.io/packages/helm/grafana/grafana
OTEL_COLLECTOR_CHART_VERSION='0.110.7'        # https://artifacthub.io/packages/helm/opentelemetry-helm/opentelemetry-collector
VAULT_CHART_VERSION='0.29.1'                  # https://artifacthub.io/packages/helm/hashicorp/vault
CERT_MANAGER_CHART_VERSION='v1.16.2'          # https://artifacthub.io/packages/helm/cert-manager/cert-manager
KUBERNETES_REPLICATOR_CHART_VERSION='2.11.0'  # https://artifacthub.io/packages/helm/kubernetes-replicator/kubernetes-replicator
ISTIO_CHART_VERSION='1.24.1'                  # https://artifacthub.io/packages/helm/istio-official/base

#------------------------------------------------------------------------------
# [i] Ports
#------------------------------------------------------------------------------

ARGOCD_PORT=30080
ARGOWF_PORT=30081

#------------------------------------------------------------------------------
# [i] Validate the command line arguments
#------------------------------------------------------------------------------

[[ $# -ne 1 || ($1 != "create" && $1 != "delete") ]] && \
{ echo "Usage: $0 <create|delete>"; exit 1; }

#------------------------------------------------------------------------------
# [i] Handle the delete command
#------------------------------------------------------------------------------

if [[ $1 == "delete" ]]; then
  argocd context --delete "${MNGR}" 2>/dev/null || true
  kind delete clusters --all
  rm -rf ./tmp/*
  exit 0
fi

#------------------------------------------------------------------------------
# [i] cloud-provider-kind
#------------------------------------------------------------------------------

blue "---[ cloud-provider-kind ]----------------------------------------------"

docker network create kind --subnet 172.18.0.0/16 2>/dev/null || true

docker ps | grep -q cp-kind || {
  docker run --rm -d \
    --name cp-kind \
    --network kind \
    --volume /var/run/docker.sock:/var/run/docker.sock \
    registry.k8s.io/cloud-provider-kind/cloud-controller-manager:v0.4.0
}

#------------------------------------------------------------------------------
# [i] Pull-through image cache
#------------------------------------------------------------------------------

blue "---[ Pull-through registries ]------------------------------------------"

docker start registry-docker.io 2>/dev/null || docker run -d \
  -e REGISTRY_PROXY_REMOTEURL=https://registry-1.docker.io \
  --restart always \
  --name registry-docker.io \
  --network kind \
  registry:2

docker start registry-quay.io 2>/dev/null || docker run -d \
  -e REGISTRY_PROXY_REMOTEURL=https://quay.io \
  --restart always \
  --name registry-quay.io \
  --network kind \
  registry:2

docker start registry-ghcr.io 2>/dev/null || docker run -d \
  -e REGISTRY_PROXY_REMOTEURL=https://ghcr.io \
  --restart always \
  --name registry-ghcr.io \
  --network kind \
  registry:2

#------------------------------------------------------------------------------
# [i] Create the clusters
#------------------------------------------------------------------------------

blue "---[ KinD clusters ]----------------------------------------------------"

# Create the temporary directory
[ -d ./tmp ] || mkdir -p ./tmp

# Configure kube-00
cat << EOF > ./tmp/kind-kube-00.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
  disableDefaultCNI: true
  kubeProxyMode: "none"
containerdConfigPatches:
  - |-
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
      endpoint = ["http://registry-docker.io:5000"]
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."quay.io"]
      endpoint = ["http://registry-quay.io:5000"]
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."ghcr.io"]
      endpoint = ["http://registry-ghcr.io:5000"]
nodes:
  - role: control-plane
    extraPortMappings:
      - containerPort: ${ARGOCD_PORT}
        hostPort: ${ARGOCD_PORT}
        protocol: TCP
      - containerPort: ${ARGOWF_PORT}
        hostPort: ${ARGOWF_PORT}
        protocol: TCP
EOF

# Configure pasta-1
cat << EOF > ./tmp/kind-pasta-1.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
  disableDefaultCNI: true
  kubeProxyMode: "none"
containerdConfigPatches:
  - |-
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
      endpoint = ["http://registry-docker.io:5000"]
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."quay.io"]
      endpoint = ["http://registry-quay.io:5000"]
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."ghcr.io"]
      endpoint = ["http://registry-ghcr.io:5000"]
EOF

# Configure pasta-2
cat << EOF > ./tmp/kind-pasta-2.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
  disableDefaultCNI: true
  kubeProxyMode: "none"
containerdConfigPatches:
  - |-
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
      endpoint = ["http://registry-docker.io:5000"]
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."quay.io"]
      endpoint = ["http://registry-quay.io:5000"]
    [plugins."io.containerd.grpc.v1.cri".registry.mirrors."ghcr.io"]
      endpoint = ["http://registry-ghcr.io:5000"]
EOF

# Create the clusters
for CLUSTER in $(list clusters all); do
  if ! kind get clusters | grep -q "${CLUSTER}"; then
    ( kind create cluster --name "${CLUSTER}" --config "./tmp/kind-${CLUSTER}.yaml" ) &
  fi
done; wait

# Get all the IPs
declare -A IP
for CLUSTER in $(list clusters all); do
  IP[${CLUSTER}]=$(docker inspect "${CLUSTER}-control-plane" |
    jq -r '.[].NetworkSettings.Networks.kind.IPAddress')
  echo "${CLUSTER} = ${IP[${CLUSTER}]}"
done

#------------------------------------------------------------------------------
# [i] Setup KUBECONFIG
#------------------------------------------------------------------------------

blue "---[ KUBECONFIG ]-------------------------------------------------------"

# Use routable IPs
for CLUSTER in $(list clusters all); do
  SERVER="https://${IP[${CLUSTER}]}:6443"; echo "Server: ${SERVER}"
  kubectl config set-cluster "kind-${CLUSTER}" --server="${SERVER}"
done

function k0 {
  kubectl --context kind-kube-00 "${@}"
}

function h0 {
  helm --kube-context kind-kube-00 "${@}"
}

#------------------------------------------------------------------------------
# [i] Helm repositories
#------------------------------------------------------------------------------

blue "---[ Helm repos ]-------------------------------------------------------"

helm repo add cilium https://helm.cilium.io/
helm repo add argo https://argoproj.github.io/argo-helm
helm repo update

#------------------------------------------------------------------------------
# [i] Install the Cilium CNI
#------------------------------------------------------------------------------

blue "---[ Cilium CNI ]--------------------------------------------------------"

# Install the Cilium CNI
for CLUSTER in $(list clusters all); do

 { helm --kube-context "kind-${CLUSTER}" \
     upgrade -i cilium cilium/cilium \
     --version "${CILIUM_CHART_VERSION}" \
     --namespace kube-system \
     --values ./charts/cilium/values.yaml \
     --values ./charts/cilium/values/"${CLUSTER}".yaml \
     --set k8sServiceHost="${IP[${CLUSTER}]}"

   kubectl --context "kind-${CLUSTER}" \
     wait --for=condition=Ready nodes \
     --all --timeout=120s; } &

done; wait

#------------------------------------------------------------------------------
# [i] Install ClusterMesh
#------------------------------------------------------------------------------

blue "---[ ClusterMesh ]------------------------------------------------------"

for CELL in $(list cells); do
  CLUS=(${CELLS[${CELL}]})
  cilium clustermesh enable --context "kind-${CLUS[0]}" --service-type LoadBalancer
  cilium clustermesh enable --context "kind-${CLUS[1]}" --service-type LoadBalancer
  cilium clustermesh connect --context "kind-${CLUS[0]}" --destination-context "kind-${CLUS[1]}"
done

#------------------------------------------------------------------------------
# [i] Setup CoreDNS server DNS entries for demo.lab
#------------------------------------------------------------------------------

blue "---[ CoreDNS ]----------------------------------------------------------"

for CLUSTER in $(list clusters); do

kubectl --context "kind-${CLUSTER}" -n kube-system create cm coredns-custom \
--dry-run=client -o yaml --from-literal=demo.server="demo.lab {
  hosts {
    ttl 60
    ${IP[${MNGR}]} vault.demo.lab
    ${IP[${MNGR}]} prometheus.demo.lab
    fallthrough
  }
}" | kubectl --context "kind-${CLUSTER}" -n kube-system apply -f -

# Restart otherwise it takes a while to pick up the new config
kubectl --context "kind-${CLUSTER}" -n kube-system rollout restart deployment coredns

done

#------------------------------------------------------------------------------
# [i] Setup ArgoCD
#------------------------------------------------------------------------------

blue "---[ ArgoCD ]-----------------------------------------------------------"

# Login to the GitHub Container Registry
echo "${GITHUB_TOKEN}" | docker login ghcr.io -u "${GITHUB_USER}" --password-stdin

# Install ArgoCD
h0 upgrade --install -n argocd --create-namespace --wait --timeout 5m \
argocd oci://ghcr.io/argoproj/argo-helm/argo-cd --version "${ARGOCD_CHART_VERSION}" \
--set 'server.service.type=NodePort' \
--set "server.service.nodePortHttp=${ARGOCD_PORT}" \
-f - << EOF | grep -E '^NAME|^LAST|^STATUS|^REVISION|^TEST'
configs:
  cm:
    resource.customizations.ignoreDifferences.admissionregistration.k8s.io_MutatingWebhookConfiguration: |
      jqPathExpressions:
      - '.webhooks[]?.clientConfig.caBundle'
EOF

# Get the password
ARGOCD_PASS=$(
  k0 -n argocd \
  get secret argocd-initial-admin-secret \
  -o jsonpath='{.data.password}' | base64 -d
)

echo
echo "ArgoCD WebUI: https://localhost:30080"
echo "ArgoCD User: admin"
echo "ArgoCD Pass: ${ARGOCD_PASS}"

#------------------------------------------------------------------------------
# [i] Register clusters to ArgoCD
#------------------------------------------------------------------------------

blue "---[ Register clusters to ArgoCD ]--------------------------------------"

# Check if the ArgoCD context exists
argocd context "${MNGR}" 2> /dev/null || {

  # Login to ArgoCD
  argocd login "${IP[${MNGR}]}:${ARGOCD_PORT}" \
    --insecure \
    --name "${MNGR}" \
    --username admin \
    --password "${ARGOCD_PASS}"

  # Add clusters with labels
  for CELL in $(list cells); do for CLUSTER in ${CELLS[${CELL}]}; do
    argocd cluster list | grep -q "${CLUSTER}" || \
    argocd cluster add -y "kind-${CLUSTER}" \
      --name "${CLUSTER}" \
      --label name="${CLUSTER}" \
      --label cell="${CELL}"
  done; done
}

#------------------------------------------------------------------------------
# [i] Install all the ApplicationSets
#------------------------------------------------------------------------------

blue "---[ ApplicationSets ]-------------------------------------------------"

helm template ./charts/cilium --set "chartVersion=${CILIUM_CHART_VERSION}" | k0 apply -f -
helm template ./charts/prometheus --set "chartVersion=${PROMETHEUS_CHART_VERSION}" | k0 apply -f -
helm template ./charts/grafana --set "chartVersion=${GRAFANA_CHART_VERSION}" | k0 apply -f -
helm template ./charts/otel-collector --set "chartVersion=${OTEL_COLLECTOR_CHART_VERSION}" | k0 apply -f -
helm template ./charts/vault --set "chartVersion=${VAULT_CHART_VERSION}" | k0 apply -f -
helm template ./charts/cert-manager --set "chartVersion=${CERT_MANAGER_CHART_VERSION}" | k0 apply -f -
helm template ./charts/kubernetes-replicator --set "chartVersion=${KUBERNETES_REPLICATOR_CHART_VERSION}" | k0 apply -f -
helm template ./charts/istio --set "chartVersion=${ISTIO_CHART_VERSION}" | k0 apply -f -

#------------------------------------------------------------------------------
# [i] Setup ArgoWF
#------------------------------------------------------------------------------

blue "---[ ArgoWF ]-----------------------------------------------------------"

# Install Argo Workflows
h0 upgrade --install -n argowf --create-namespace --wait --timeout 5m \
  argo-workflows argo/argo-workflows --version "${ARGOWF_CHART_VERSION}" \
  --set 'server.serviceType=NodePort' \
  --set "server.serviceNodePort=${ARGOWF_PORT}" \
  --set 'server.authModes={server}' \
  --set 'workflow.serviceAccount.create=true' \
  --set 'workflow.serviceAccount.name=argo-workflow' \
  --set 'workflow.rbac.create=true' \
  --set 'controller.workflowNamespaces={argocd}' |
  grep -E '^NAME|^LAST|^STATUS|^REVISION|^TEST'

# Patch the argo-workflow-role to allow patching of the ApplicationSets
k0 -n argocd patch role argo-workflows-workflow --type json \
  -p '[
        {
          "op": "add",
          "path": "/rules/-",
          "value": {
            "apiGroups":["argoproj.io"],
            "resources":["applicationsets"],
            "verbs":["get","watch","patch"]
          }
        }
      ]'

echo
echo "ArgoWF WebUI: http://localhost:${ARGOWF_PORT}"

#------------------------------------------------------------------------------
# [i] Bootstrap DAG
#------------------------------------------------------------------------------

blue "---[ Bootstrap DAG ]----------------------------------------------------"

# Install Argo WorkflowTemplates
helm template ./charts/wftemplates | k0 -n argocd apply -f -

# Create a secret with ArgoCD credentials
k0 create secret generic argocd-credentials \
 --from-literal=password="${ARGOCD_PASS}" \
 --from-literal=username='admin' \
 --from-literal=token='' \
 --dry-run=client -o yaml | k0 -n argocd apply -f -

# Create the bootstrap workflow
argo --context kind-kube-00 list -n argocd | grep -q bootstrap || \
argo --context kind-kube-00 submit -n argocd -w - << EOF
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: bootstrap-
spec:
  entrypoint: stages
  serviceAccountName: argo-workflow
  templates:
  - name: stages
    dag:
      tasks:
      - name: cilium
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=cilium
      - name: prometheus
        dependencies: [cilium]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=prometheus
      - name: grafana
        dependencies: [prometheus]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=grafana
      - name: otelco-node
        dependencies: [prometheus]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=otelco-node
      - name: otelco-cluster
        dependencies: [prometheus]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=otelco-cluster
      - name: vault
        dependencies: [cilium]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=vault
      - name: cert-manager
        dependencies: [cilium]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=cert-manager
      - name: kubernetes-replicator
        dependencies: [cilium]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=kubernetes-replicator
      - name: populate-vault
        dependencies: [vault]
        templateRef:
          name: populate-vault
          template: populate-vault
      - name: istio-issuers
        dependencies: [populate-vault, cert-manager]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=istio-issuers
      - name: istio-base
        dependencies: [cilium]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=istio-base
      - name: istio-cni
        dependencies: [istio-base]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=istio-cni
      - name: istio-istiod
        dependencies: [istio-base, istio-issuers]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=istio-istiod
      - name: istio-ztunnel
        dependencies: [istio-istiod]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=istio-ztunnel
      - name: istio-nsgw
        dependencies: [istio-istiod]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=istio-nsgw
      - name: istio-ewgw
        dependencies: [istio-istiod]
        templateRef:
          name: argocd-sync-and-wait
          template: argocd-sync-and-wait
        arguments:
          parameters:
          - name: selectors
            value: name=istio-ewgw
EOF
